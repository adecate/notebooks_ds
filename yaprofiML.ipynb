{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.6",
      "language": "python",
      "name": "python3.8.6"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "yaprofiML.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FyPoprube_at",
        "outputId": "a6c98974-6dc5-4b7f-efee-10ff6e7d297d"
      },
      "source": [
        "import pandas as pd\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from copy import copy\n",
        "from sklearn.metrics import accuracy_score\n",
        "plotly.offline.init_notebook_mode(connected = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-czEOHue_a1"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03YdDHghfkNP"
      },
      "source": [
        "train = pd.read_csv('Training_wells.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3r6fVMZe_a2"
      },
      "source": [
        "# дропаем колонки, в которых есть хотя бы один нан\n",
        "dropList_numeric = []\n",
        "dropList_categorial = []\n",
        "for colname, colvalue in zip(initial_dataset.columns, initial_dataset.isnull().any()):\n",
        "    if colvalue == True and np.issubdtype(initial_dataset[colname].dtype, np.number) == True:\n",
        "        dropList_numeric.append(colname)\n",
        "    elif colvalue == True and not np.issubdtype(initial_dataset[colname].dtype, np.number):\n",
        "        dropList_categorial.append(colname)\n",
        "dataset = initial_dataset.drop(dropList_numeric + dropList_categorial, axis = 1)\n",
        "\n",
        "# записываем координаты в отдельные переменные и выбрасываем их из датасета\n",
        "latitude = dataset['7. Latitude']\n",
        "longitude = dataset['8. Longitude']\n",
        "dataset = dataset.drop(['7. Latitude', '8. Longitude', '9. Operator company'], axis = 1)\n",
        "dataset = dataset.drop(dataset.columns[1:6], axis = 1) # ещё выбросимненужные данные\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnhHhnste_a2"
      },
      "source": [
        "# выделяем категориальные и непрерывные признаки\n",
        "categorial_parameters = []\n",
        "numeric_parameters = []\n",
        "for column in dataset.columns[1:]:\n",
        "    if np.issubdtype(dataset[column].dtype, np.number):\n",
        "        numeric_parameters.append(column)\n",
        "    elif dataset[column].dtype == object:\n",
        "        categorial_parameters.append(column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1cmcCXne_a3"
      },
      "source": [
        "# шифруем лейбл-энкодером все категориальные признаки\n",
        "le = LabelEncoder()\n",
        "for cat_col in categorial_parameters:\n",
        "    dataset[cat_col] = le.fit_transform(dataset[cat_col])\n",
        "    initial_dataset[cat_col] = le.fit_transform(initial_dataset[cat_col])\n",
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lNYAbvWe_a3"
      },
      "source": [
        "# кластеризуем\n",
        "distance_matr = squareform(pdist(train.iloc[:, 1:], metric = 'jaccard'))\n",
        "\n",
        "clust = SpectralClustering()\n",
        "\n",
        "clst_labels = clust.fit_predict(distance_matr)\n",
        "labels_set = list(set(clst_labels))\n",
        "print(labels_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64cS6QwUe_a4"
      },
      "source": [
        "# восстанавливаем значения во всех колонках по месторождениям-аналогам\n",
        "for dropped_col in dropList_numeric: # числовые\n",
        "    print(\"Осредняем по аналогам (числа)\")\n",
        "    subDf = initial_dataset[initial_dataset[dropped_col].isnull()]\n",
        "    for classy in subDf.groupby('Class')['Class'].unique():\n",
        "        print(\"Класс {}\".format(classy))\n",
        "        similar_values_list = initial_dataset[initial_dataset['Class'] == classy[0]][dropped_col]\n",
        "        if len(similar_values_list) > 1:\n",
        "            missed_val = similar_values_list.dropna().mean()\n",
        "            print(missed_val)\n",
        "            initial_dataset.loc[similar_values_list[similar_values_list.isnull()].index, dropped_col] = missed_val\n",
        "            \n",
        "for dropped_col in dropList_categorial: # категориальные\n",
        "    print(\"Осредняем по аналогам (категории)\")\n",
        "    subDF = initial_dataset[initial_dataset[dropped_col].isnull()]\n",
        "    for classy in subDf.groupby('Class')['Class'].unique():\n",
        "        print(\"Класс {}\".format(classy))\n",
        "        similar_values_list = initial_dataset[initial_dataset['Class'] == classy[0]][dropped_col]\n",
        "        missed_val = similar_values_list.value_counts()[similar_values_list.value_counts() == similar_values_list.value_counts().max()].index\n",
        "        print(missed_val[0])\n",
        "        initial_dataset.loc[similar_values_list[similar_values_list.isnull()].index, dropped_col] = missed_val[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZploFPpLe_a5"
      },
      "source": [
        "print(initial_dataset)\n",
        "initial_dataset.to_csv('recovered_dataset.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOYhBg01e_a5"
      },
      "source": [
        "def r2(yi_list, fi_list):\n",
        "    y_mean = sum(yi_list) / float(len(yi_list))\n",
        "    ss_tot = sum((yi - y_mean) ** 2 for yi in yi_list)\n",
        "    ss_err = sum((yi - fi) ** 2 for yi, fi in zip(yi_list, fi_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2APb0o3e_a5"
      },
      "source": [
        "answer = pd.read_csv('dataset_for_check.csv')\n",
        "response = copy(initial_datset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GPDsIpKe_a5"
      },
      "source": [
        "acc = 0\n",
        "R_2 = 0\n",
        "if (len(answer[1:]) != len(response[1:])):\n",
        "    print(\"Error!\")\n",
        "else:\n",
        "    acc = accuracy_score(answer['6. Tectonic regime'].values, response['6. Tectonic regime'].values)\n",
        "\n",
        "porosity_answer = answer['19. Porosity (matrix average %)'].values\n",
        "\n",
        "porosity_response = response['19. Porosity (matrix average %)'].values\n",
        "\n",
        "R_2 = r2(porosity_answer, porosity_response)\n",
        "\n",
        "print(acc, R_2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}